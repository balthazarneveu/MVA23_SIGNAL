{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c235e40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import h5py # pour gérer les formats de données utilisés ici \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa84c0",
   "metadata": {},
   "source": [
    "# TP3: Reconnaissance de signaux de communication par apprentissage profond \n",
    "\n",
    "Mathilde Dupouy\n",
    "\n",
    "Balthazar Neveu\n",
    "\n",
    "Au moment du rendu, le notebook doit être nommé nom1_nom2_dlts_tp3.ipynb \n",
    "\n",
    "3 séances de TP sur ce sujet : le 15 novembre (1h00), le 22 novembre (3h) et le 29 novembre (3h).<br> \n",
    "Deadline : 6 décembre 2023, 11h59, par mail à deepetsignal.mva@gmail.com <br> \n",
    "\n",
    "Pour installer les paquets nécessaires à la réalisation de ce TP vous pouvez utiliser dans le notebook \n",
    "    \n",
    "```\n",
    "!pip install \\< nom_du_paquet \\>\n",
    "```\n",
    "merci de regrouper toutes les installations dans la première cellule du notebook. \n",
    "Essayez de faire en sorte que votre notebook puisse se lire comme un compte rendu, évitez de laisser du code mort et prennez le temps de commenter vos observations et résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2747407a",
   "metadata": {},
   "source": [
    "## Problématique\n",
    "\n",
    "On cherche à identifier un type d'émetteur de communication à partir de l'observation d'un signal provenant de l'émetteur \n",
    "de 2048 échantillons IQ (In Phase / Quadrature) ie le signal prend des valeurs complexes. On représente la partie \n",
    "réelle et la partie imaginaire du signal par deux canaux réel d'un signal multivarié. \n",
    "\n",
    "L'émetteur peut provenir de 6 catégories différentes. \n",
    "Les paramètres différenciant les différentes catégories sont \n",
    "- le type de modulation \n",
    "- la présence ou non de séquences pilotes et le cas échéant la structure de trame pilotes / données \n",
    "- le débit de la transmission \n",
    "\n",
    "Les signaux se propagent en champs libre et sont enregistrés par une antenne. Le signal reçu est transposé en bande de base c'est à dire que si le signal est transmis autour d'une fréquence centrale f0, une première étape de traitement du signal à la réception recentre le signal autour de la fréquence 0. \n",
    "\n",
    "\n",
    "Les différents signaux observés dans ce TP sont entachés de différentes erreurs caractéristiques de la propagation \n",
    "électromagnétiques comme : \n",
    "- modification aléatoire de la phase du signal lors de la transmission\n",
    "- imperfection de la transposition en bande de base qui laisse le signal transposé à une fréquence df0 << f0\n",
    "- présence d'interférence entre les symboles transmis (dûes par exemple à plusieurs chemins de propagation)\n",
    "- présence d'un bruit blanc additif gaussien\n",
    "\n",
    "Le niveau du bruit relativement à celui du signal utile est décrit par le SNR (Signal to Noise Ratio) et exprimé en dB. On suppose que le SNR est connu lors de l'acquisition d'un signal. Lors de ce TP nous rencontrerons 4 niveaux de SNR: 30 dB (facile), 20 dB, 10 dB et 0 dB (en espérant qu'on puisse faire quelque chose de ces données). \n",
    "Un de nos objectifs sera de qualifier la performance des algorithmes mis en place en fonction du SNR.\n",
    "\n",
    "Les objectifs de ce TP sont: \n",
    "1/ Définir une ou plusieurs architectures de réseaux de neurones profonds et les implémenter en PyTorch\n",
    "2/ Entrainer ces architectures, la fonction de perte employée pourra être la log vraisemblance négative: https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html. \n",
    "3/ Qualifier les performances de votre réseau de neurones sur l'ensemble de test via: \n",
    "   - Le calcul de l'accuracy implémentée par exemple dans le package TorchMetrics (https://torchmetrics.readthedocs.io/en/stable/classification/accuracy.html)\n",
    "   - La réalisation d'un graphique accuracy vs SNR \n",
    "   - La réalisation des matrices de confusion entre les différentes classes pour les différents SNR (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix)\n",
    "\n",
    "Durant l'entraînement on observera l'évolution de la fonction de perte et de l'accuracy sur l'ensemble d'entraînement et sur l'ensemble de validation. \n",
    "\n",
    "\n",
    "Les 4 premières parties sont un échauffement sur lequel vous pouvez passer vite si vous êtes à l'aise avec le sujet. \n",
    "Le gros du travail est dans la partie 5 \"Entraînemenent d'un réseau de neurones\". \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4865e6",
   "metadata": {},
   "source": [
    "## Chargement des données en numpy\n",
    "\n",
    "Le TP est composé de trois jeux de données : \n",
    "- train.hdf5 destiné à nourrir l'entrainement de réseaux de neurones \n",
    "- test.hdf5 destiné à évaluer les algorithmes après entrainement\n",
    "- samples.hdf5 qui est beaucoup plus petit que train.hdf5 et destiné à servir de modèle de données dans une phase de prototypage \n",
    "des algorithmes et de la pipeline d'entrainement\n",
    "\n",
    "Les trois jeux de données sont au format hdf5 qui peut être manipulé via l'API Python h5py https://docs.h5py.org/en/stable/quick.html.\n",
    "Un fichier hdf5 est consitué d'une arborescence de datasets et de groups. Un dataset hdf5 représente un tenseur n dimensionnel. Un dataset se convertit très facilement en numpy array.\n",
    "\n",
    "Par exemple vous pouvez charger les données samples selon la cellule suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(open_h5_file): \n",
    "    return {\n",
    "        open_h5_file['label_name'].attrs[k] : k\n",
    "        for k in open_h5_file['label_name'].attrs.keys()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "803ab62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "DATA = Path(\"data\")\n",
    "data_path = DATA/\"samples.hdf5\"\n",
    "assert data_path.exists()\n",
    "data = h5py.File(data_path , 'r')\n",
    "\n",
    "signals = np.array(data['signaux'])\n",
    "snr =  np.array(data['snr'])\n",
    "labels_id = np.array(data['labels'])\n",
    "label_dict = get_labels(data)\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66630a9e",
   "metadata": {},
   "source": [
    "Vous pouvez récupérer le nom de la correspondance entre un label et le nom du standard d'émetteur correspondant via:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c61acbe",
   "metadata": {},
   "source": [
    "### Visualisation des données \n",
    "\n",
    "Commencez par étudier les données: \n",
    "\n",
    "    - observez leur taille \n",
    "    - la distribution des différentes classes et des différents SNR dans l'ensemble d'entrainement \n",
    "    - visualisez quelques signaux bien choisis selon une ou des représentations que vous choisirez "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f0a2f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2cef7fb6294969b598ea157905a90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='idx', max=199), Output()), _dom_classes=('widget-interac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "import matplotlib.pyplot as plt\n",
    "def visualize(idx):\n",
    "    # plt.plot(signals[idx, :, 0], label=\"real\")\n",
    "    # plt.plot(signals[idx, :, 1], label=\"imaginary\")\n",
    "    plt.scatter(signals[idx, :, 0], signals[idx, :, 1], label=\"complex\", alpha=0.5)\n",
    "    plt.title(f'{label_dict.get(labels_id[idx], \"unknown\")} SNR={snr[idx]} db')\n",
    "    plt.legend()\n",
    "    plt.xlim(-3, 3)\n",
    "    plt.ylim(-3, 3)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "interact(visualize, idx=IntSlider(min=0, max=signals.shape[0]-1, step=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(labels_id, bins=6, label=label_dict)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9fa901",
   "metadata": {},
   "source": [
    "## Chargement des données en Pytorch\n",
    "\n",
    "Pour entrainer des réseaux de neurones profond sur nos données nous allons utiliser le framework Pytorch. \n",
    "Une première étape va consister à transférer les données de numpy à PyTorch, cela passe par deux objets : \n",
    "    - un Dataset qui modélise le dataset à haut niveau dans la mémoire de l'ordinateur\n",
    "    - un Dataloader qui permet d'échantillonner le Dataset Pytorch dans les itérations de l'optimisation du réseau de neurones \n",
    "    \n",
    "Un dataset prend la forme \n",
    "```python\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, path_to_data):\n",
    "        ...\n",
    "    def __len__(self): #retourne le nombre de données dans le dataset\n",
    "        ...\n",
    "    def __getitem__(self,i): #retourne pour chaque indice i un couple (data_i, lablel_i), data_i étant un signal et label_i le label associé au signal\n",
    "        ...\n",
    "```\n",
    "\n",
    "Implémentez une classe Dataset pour le dataset considéré ici "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53406fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader():\n",
    "    def __init__(self, path: Path):\n",
    "        self.path = path\n",
    "        assert path.exists()\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69069805",
   "metadata": {},
   "source": [
    "Instanciez un objet dataset et testez le sur les données samples\n",
    "```python\n",
    "dataset = MyDataset(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144c1e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c6532b5",
   "metadata": {},
   "source": [
    "Pytorch propose une classe Dataloader qui permet d'échantillonner des batchs de taille fixe à partir d'un dataset. \n",
    "La cellule suivante donne un exemple d'utilisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3044a289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(dataset, \n",
    "                        batch_size=10, \n",
    "                        shuffle=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037f1b6e",
   "metadata": {},
   "source": [
    "Testez le dataloader pour différentes valeurs de batch_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965210fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb7a7c17",
   "metadata": {},
   "source": [
    "## Mise en place d'un réseau \"dumb\" pour tester la pipeline d'entrainement\n",
    "\n",
    "Définissez un premier modèle Pytorch qui prend en entrée un batch de données (tenseur de dimensions [B , C, T] avec B la taille du batch, C le nombre de canaux des signaux et T le nombre d'échantillons dans les signaux) et renvoie un batch de vecteur de probabilités (ou de log probabilités si vous préférez) (tenseur de dimensions [B,N] où N est le nombre de classe à identifier). \n",
    "\n",
    "Ce Modèle doit être très simple, il doit être rapide à exécuter, il servira à tester et éventuellement débugger la pipeline d'entrainement que vous mettrez en place un peu plus loin. Un template d'implémentation d'une classe Model se trouve dans les diapositives du cours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8710cd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8767db4",
   "metadata": {},
   "source": [
    "Instanciez votre modèle et testez la consistence de ses entrées / sorties vis à vis des données étudiées "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d3766f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "617dcb82",
   "metadata": {},
   "source": [
    "## Mise en place de la pipeline d'entraînement\n",
    "\n",
    "La pipeline d'entrainement consiste à \n",
    "- charger les données \n",
    "- les batcher \n",
    "- réaliser des itération (epochs) de descente de gradient pour optimiser les paramètres d'un algorithme selon une fonction de perte (loss)\n",
    "- logger l'évolution au fil des epochs  de la loss sur l'ensemble train et l'ensemble de validation et éventuellement de métriques complémentaires \n",
    "\n",
    "Un cavnevas d'implémentation pourrait être:\n",
    "\n",
    "```python\n",
    "device = 'cpu' # set so 'cuda:xx' if you have a GPU, xx is GPU index. L'entraînement des réseaux de neurones est grandement accéléré par l'utilisation d'un GPU \n",
    "\n",
    "model = ...  # vous instanciez ici votre modèle\n",
    "\n",
    "loss = .... # définissez la fonction de perte selon laquelle le modèle sera optimisé\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters()) # en pratique on utilise pas une simple descente de gradient mais une procédure d'optimisation plus sophistiquée qui est implémentée sous la forme d'un objet Optimizer. Il en existe beaucoup d'optimizers différents, vous pouvez en tester différents, je vous propose d'utiliser en premier lieu l'algorithme Adam\n",
    "\n",
    "n_epochs = ... # le nombre d'itérations dans l'entrainement \n",
    "\n",
    "chemin_vers_sauvegarde_model = # chemin vers un fichier où vous sauvegarderez votre modèle après optimisation pour le réutiliser plus tard. \n",
    "\n",
    "model.to(device) # on place le modèle dans le GPU si nécessaire\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    for batch_x,batch_y in dataloader_train:\n",
    "        \n",
    "        batch_x.to(device)\n",
    "        batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_y_predicted = model(batch_x)\n",
    "        \n",
    "        l = loss(batch_y_predicted, batch_y)\n",
    "        # loggez la loss sur le batch d'entraînement\n",
    "        \n",
    "        l.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    for batch_x,batch_y in dataloader_valid:\n",
    "        \n",
    "        batch_x.to(device)\n",
    "        batch_y.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_y_predicted = model(batch_x)  \n",
    "            \n",
    "        # loggez la loss et les métriques sur le batch de validation\n",
    "\n",
    "torch.save(model, chemin_vers_sauvegarde_model)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c67127",
   "metadata": {},
   "source": [
    "Mettez en place votre pipeline et testez là sur votre modèle dumb. Faites en sorte que votre façon de logger les loss et les métriques vous permette de visualiser l'évolution de ces différents indicateurs sur l'ensemble d'entrainement et de validation au fil des epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8ffa16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a455335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4994ac40",
   "metadata": {},
   "source": [
    "Vérifiez que vous avez bien enregistré votre modèle en fin d'entrainement. Chargez le avec la fonction \n",
    "```python\n",
    "modele = torch.load(...) \n",
    "```\n",
    "et vérifiez que vous pouvez l'utiliser sur des données du problème."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e164707e",
   "metadata": {},
   "source": [
    "## Entraînement de réseaux de neurones\n",
    "\n",
    "Dans cette partie vous définissez une ou plusieurs architecture de réseaux de neurones profonds et vous les réglez sur les données d'entrainement. \n",
    "Vous pouvez notamment utiliser des réseaux à base de convolutions et/ou de couches réurrentes. Vous pouvez vous inspirer de ce qui a été dit en cours sur la reconnaissance vocale.\n",
    "\n",
    "Vous pouvez si vous le souhaitez mettre en place des stratégies d'augmentation de données pour améliorer vos résultats. Pour mettre l'augmentation de données en pratique pouvez vous renseigner sur l'argument collate_fn du dataloader standard de Pytorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a914bb87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46810f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "878c3943",
   "metadata": {},
   "source": [
    "## Synthèse de résultats \n",
    "\n",
    "Une fois que votre ou vos réseaux sont entrainez vous comparez leurs performances selon les métriques définies en introduction sur l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbac3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dda3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
